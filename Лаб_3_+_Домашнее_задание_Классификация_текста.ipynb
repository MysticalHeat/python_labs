{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MysticalHeat/python_labs/blob/main/%D0%9B%D0%B0%D0%B1_3_%2B_%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D0%B5%D0%B5_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItXfxkxvosLH"
      },
      "source": [
        "# Базовая классификация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKY4XMc9o8iB"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg62Pmz3o83v"
      },
      "source": [
        "В этом файле демонстрируется классификация текста, начиная с обычных текстовых файлов, хранящихся на диске. Вы обучите двоичный классификатор выполнять анализ настроений в наборе данных IMDB.\n",
        "\n",
        "**В конце блокнота вы можете попробовать выполнить упражнение, в котором вы научите многоклассовый классификатор предсказывать тег для вопроса по программированию в Stack Overflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:29:38.082944Z",
          "iopub.status.busy": "2023-07-27T05:29:38.082384Z",
          "iopub.status.idle": "2023-07-27T05:29:40.613085Z",
          "shell.execute_reply": "2023-07-27T05:29:40.612356Z"
        },
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-27T05:29:40.617007Z",
          "iopub.status.busy": "2023-07-27T05:29:40.616615Z",
          "iopub.status.idle": "2023-07-27T05:29:40.620520Z",
          "shell.execute_reply": "2023-07-27T05:29:40.619886Z"
        },
        "id": "6-tTFS04dChr",
        "outputId": "09f265c3-4c6f-4db0-80b0-55c93a80ec58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBTI1bi8qdFV"
      },
      "source": [
        "## Анализ настроений\n",
        "\n",
        "Этот блокнот обучает модель анализа настроений классифицировать рецензии на фильмы как *положительные* или *негативные* в зависимости от текста рецензии. Это пример *бинарной* (или двухклассовой) классификации, важной и широко применимой задачи машинного обучения.\n",
        "\n",
        "Вы будете использовать [Большой набор данных обзоров фильмов](https://ai.stanford.edu/~amaas/data/sentiment/), который содержит текст 50 000 обзоров фильмов из [Интернет-базы данных фильмов](https:// www.imdb.com/). Они разделены на 25 000 отзывов для обучения и 25 000 отзывов для тестирования. Наборы для обучения и тестирования *сбалансированы*, то есть содержат равное количество положительных и отрицательных отзывов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsKG535pHep"
      },
      "source": [
        "### Загрузите и изучите набор данных IMDB\n",
        "\n",
        "Давайте загрузим и извлечем набор данных, а затем исследуем структуру каталогов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:29:40.659007Z",
          "iopub.status.busy": "2023-07-27T05:29:40.658763Z",
          "iopub.status.idle": "2023-07-27T05:30:01.271044Z",
          "shell.execute_reply": "2023-07-27T05:30:01.270254Z"
        },
        "id": "k7ZYnuajVlFN"
      },
      "outputs": [],
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join('/content', 'aclImdb_v1', 'aclImdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:01.274625Z",
          "iopub.status.busy": "2023-07-27T05:30:01.274373Z",
          "iopub.status.idle": "2023-07-27T05:30:01.280557Z",
          "shell.execute_reply": "2023-07-27T05:30:01.279978Z"
        },
        "id": "355CfOvsV1pl",
        "outputId": "ba0bb033-9591-4c8f-876c-e9377cc9e39d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imdb.vocab', 'imdbEr.txt', 'test', 'README', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:01.283308Z",
          "iopub.status.busy": "2023-07-27T05:30:01.283094Z",
          "iopub.status.idle": "2023-07-27T05:30:01.287355Z",
          "shell.execute_reply": "2023-07-27T05:30:01.286818Z"
        },
        "id": "7ASND15oXpF1",
        "outputId": "561b5673-ea66-4da2-cbb7-208e5a5358d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg',\n",
              " 'unsup',\n",
              " 'urls_unsup.txt',\n",
              " 'urls_pos.txt',\n",
              " 'urls_neg.txt',\n",
              " 'pos',\n",
              " 'labeledBow.feat',\n",
              " 'unsupBow.feat']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysMNMI1CWDFD"
      },
      "source": [
        "Каталоги `aclImdb/train/pos` и `aclImdb/train/neg` содержат множество текстовых файлов, каждый из которых представляет собой отдельную рецензию на фильм. Давайте взглянем на один из них."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:01.289975Z",
          "iopub.status.busy": "2023-07-27T05:30:01.289752Z",
          "iopub.status.idle": "2023-07-27T05:30:01.293529Z",
          "shell.execute_reply": "2023-07-27T05:30:01.293058Z"
        },
        "id": "R7g8hFvzWLIZ",
        "outputId": "76c07b0d-106a-471a-df5b-99532b7eee48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
          ]
        }
      ],
      "source": [
        "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
        "with open(sample_file) as f:\n",
        "  print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk20TEm6ZRFP"
      },
      "source": [
        "### Загрузите набор данных\n",
        "\n",
        "Далее вы загрузите данные с диска и преобразуете их в формат, подходящий для обучения. Для этого вы воспользуетесь полезной утилитой [text_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text_dataset_from_directory), которая ожидает следующую структуру каталогов.\n",
        "\n",
        "```\n",
        "main_directory/\n",
        "...class_a/\n",
        "......a_text_1.txt\n",
        "......a_text_2.txt\n",
        "...class_b/\n",
        "......b_text_1.txt\n",
        "......b_text_2.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQauv38Lnok3"
      },
      "source": [
        "Чтобы подготовить набор данных для бинарной классификации, вам понадобятся две папки на диске, соответствующие «class_a» и «class_b». Это будут положительные и отрицательные рецензии на фильмы, которые можно найти в `aclImdb/train/pos` и `aclImdb/train/neg`. Поскольку набор данных IMDB содержит дополнительные папки, вы удалите их перед использованием этой утилиты.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:01.296256Z",
          "iopub.status.busy": "2023-07-27T05:30:01.296046Z",
          "iopub.status.idle": "2023-07-27T05:30:02.116623Z",
          "shell.execute_reply": "2023-07-27T05:30:02.115853Z"
        },
        "id": "VhejsClzaWfl"
      },
      "outputs": [],
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95kkUdRoaeMw"
      },
      "source": [
        "Далее вы воспользуетесь утилитой text_dataset_from_directory для создания файла с меткой tf.data.Dataset. [tf.data](https://www.tensorflow.org/guide/data) — мощный набор инструментов для работы с данными.\n",
        "\n",
        "При проведении эксперимента по машинному обучению рекомендуется разделить набор данных на три части: [train](https://developers.google.com/machine-learning/glossary#training_set), [validation](https:/ /developers.google.com/machine-learning/glossary#validation_set) и [test](https://developers.google.com/machine-learning/glossary#test-set).\n",
        "\n",
        "Набор данных IMDB уже разделен на обучающий и тестовый, но в нем отсутствует набор проверки. Давайте создадим набор проверки, используя разделение обучающих данных 80:20, используя приведенный ниже аргумент validation_split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:02.120613Z",
          "iopub.status.busy": "2023-07-27T05:30:02.120345Z",
          "iopub.status.idle": "2023-07-27T05:30:06.648612Z",
          "shell.execute_reply": "2023-07-27T05:30:06.647926Z"
        },
        "id": "nOrK-MTYaw3C",
        "outputId": "1bed9895-44db-43ca-8c34-98045a6df443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/aclImdb_v1/aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y33oxOUpYkh"
      },
      "source": [
        "Как вы можете видеть выше, в папке обучения находится 25 000 примеров, из которых вы будете использовать 80% (или 20 000) для обучения. Как вы вскоре увидите, вы можете обучить модель, передав набор данных непосредственно в model.fit. Если вы новичок в `tf.data`, вы также можете перебрать набор данных и распечатать несколько примеров, как показано ниже.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:06.652079Z",
          "iopub.status.busy": "2023-07-27T05:30:06.651830Z",
          "iopub.status.idle": "2023-07-27T05:30:06.679532Z",
          "shell.execute_reply": "2023-07-27T05:30:06.678895Z"
        },
        "id": "51wNaPPApk1K"
      },
      "outputs": [],
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(\"Review\", text_batch.numpy()[i])\n",
        "    print(\"Label\", label_batch.numpy()[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWq1SUIrp1a-"
      },
      "source": [
        "Обратите внимание, что отзывы содержат необработанный текст (со знаками препинания и редкими HTML-тегами, такими как `<br/>`). В следующем разделе вы покажете, как с ними справиться.\n",
        "\n",
        "Метки — 0 или 1. Чтобы узнать, какие из них соответствуют положительным и отрицательным обзорам фильмов, вы можете проверить свойство class_names в наборе данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:06.682685Z",
          "iopub.status.busy": "2023-07-27T05:30:06.682148Z",
          "iopub.status.idle": "2023-07-27T05:30:06.685884Z",
          "shell.execute_reply": "2023-07-27T05:30:06.685275Z"
        },
        "id": "MlICTG8spyO2"
      },
      "outputs": [],
      "source": [
        "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
        "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbdO39vYqdJr"
      },
      "source": [
        "Далее вы создадите набор данных для проверки и тестирования. Для проверки вы будете использовать оставшиеся 5000 отзывов из обучающего набора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzxazN8Hq1pF"
      },
      "source": [
        "Примечание. При использовании аргументов validation_split и subset обязательно укажите случайное начальное значение или передайте shuffle=False, чтобы разделения проверки и обучения не перекрывались."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:06.688841Z",
          "iopub.status.busy": "2023-07-27T05:30:06.688613Z",
          "iopub.status.idle": "2023-07-27T05:30:07.813603Z",
          "shell.execute_reply": "2023-07-27T05:30:07.812982Z"
        },
        "id": "JsMwwhOoqjKF"
      },
      "outputs": [],
      "source": [
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:07.816810Z",
          "iopub.status.busy": "2023-07-27T05:30:07.816570Z",
          "iopub.status.idle": "2023-07-27T05:30:08.980337Z",
          "shell.execute_reply": "2023-07-27T05:30:08.979665Z"
        },
        "id": "rdSr0Nt3q_ns"
      },
      "outputs": [],
      "source": [
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJmTiO0IYAjm"
      },
      "source": [
        "### Подготовьте набор данных для обучения\n",
        "\n",
        "Далее вы стандартизируете, токенизируете и векторизуете данные, используя полезный слой tf.keras.layers.TextVectorization.\n",
        "\n",
        "Стандартизация подразумевает предварительную обработку текста, обычно для удаления знаков препинания или элементов HTML для упрощения набора данных. Токенизация означает разделение строк на токены (например, разделение предложения на отдельные слова путем разделения на пробелы). Векторизация означает преобразование токенов в числа, чтобы их можно было передать в нейронную сеть. Все эти задачи могут быть выполнены с помощью этого слоя.\n",
        "\n",
        "Как вы видели выше, отзывы содержат различные HTML-теги, например `<br />`. Эти теги не будут удалены стандартизатором по умолчанию на слое TextVectorization (который по умолчанию преобразует текст в нижний регистр и удаляет пунктуацию, но не удаляет HTML). Вы напишете собственную функцию стандартизации для удаления HTML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVcHl-SLrH-u"
      },
      "source": [
        "Примечание. Чтобы предотвратить [неравномерность обучения и тестирования](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew) (также известную как неравномерность обучения и обслуживания), важно для идентичной предварительной обработки данных во время обучения и тестирования. Чтобы облегчить это, слой TextVectorization можно включить непосредственно в вашу модель, как показано далее в этом уроке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:08.984097Z",
          "iopub.status.busy": "2023-07-27T05:30:08.983857Z",
          "iopub.status.idle": "2023-07-27T05:30:08.987756Z",
          "shell.execute_reply": "2023-07-27T05:30:08.987167Z"
        },
        "id": "SDRI_s_tX1Hk"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2d3Aw8dsUux"
      },
      "source": [
        "Далее вы создадите слой TextVectorization. Вы будете использовать этот слой для стандартизации, токенизации и векторизации наших данных. Вы устанавливаете для параметра «output_mode» значение «int», чтобы создавать уникальные целочисленные индексы для каждого токена.\n",
        "\n",
        "Обратите внимание, что вы используете функцию разделения по умолчанию и пользовательскую функцию стандартизации, определенную выше. Вы также определите некоторые константы для модели, такие как явная максимальная `sequence_length`, которая заставит слой дополнять или усекать последовательности точно до значений `sequence_length`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:08.990592Z",
          "iopub.status.busy": "2023-07-27T05:30:08.990355Z",
          "iopub.status.idle": "2023-07-27T05:30:09.005276Z",
          "shell.execute_reply": "2023-07-27T05:30:09.004672Z"
        },
        "id": "-c76RvSzsMnX"
      },
      "outputs": [],
      "source": [
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlFOpfF6scT6"
      },
      "source": [
        "Затем вы вызовете «адаптацию», чтобы подогнать состояние слоя предварительной обработки к набору данных. Это заставит модель построить индекс строк для целых чисел.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAhdjK7AtroA"
      },
      "source": [
        "Примечание. Важно использовать данные обучения только при вызове адаптации (использование набора тестов приведет к утечке информации)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:09.008376Z",
          "iopub.status.busy": "2023-07-27T05:30:09.008158Z",
          "iopub.status.idle": "2023-07-27T05:30:11.284466Z",
          "shell.execute_reply": "2023-07-27T05:30:11.283730Z"
        },
        "id": "GH4_2ZGJsa_X"
      },
      "outputs": [],
      "source": [
        "# Make a text-only dataset (without labels), then call adapt\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHQVEFzNt-K_"
      },
      "source": [
        "Давайте создадим функцию, чтобы увидеть результат использования этого слоя для предварительной обработки некоторых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.288792Z",
          "iopub.status.busy": "2023-07-27T05:30:11.288546Z",
          "iopub.status.idle": "2023-07-27T05:30:11.292217Z",
          "shell.execute_reply": "2023-07-27T05:30:11.291582Z"
        },
        "id": "SCIg_T50wOCU"
      },
      "outputs": [],
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.295302Z",
          "iopub.status.busy": "2023-07-27T05:30:11.295059Z",
          "iopub.status.idle": "2023-07-27T05:30:11.354878Z",
          "shell.execute_reply": "2023-07-27T05:30:11.354202Z"
        },
        "id": "XULcm6B3xQIO"
      },
      "outputs": [],
      "source": [
        "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", raw_train_ds.class_names[first_label])\n",
        "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u5EX0hxyNZT"
      },
      "source": [
        "Как вы можете видеть выше, каждый токен был заменен целым числом. Вы можете найти токен (строку), которому соответствует каждое целое число, вызвав `.get_vocabulary()` на слое."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.357873Z",
          "iopub.status.busy": "2023-07-27T05:30:11.357633Z",
          "iopub.status.idle": "2023-07-27T05:30:11.407060Z",
          "shell.execute_reply": "2023-07-27T05:30:11.406381Z"
        },
        "id": "kRq9hTQzhVhW"
      },
      "outputs": [],
      "source": [
        "print(\" 1346 ---> \",vectorize_layer.get_vocabulary()[1346])\n",
        "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn-4Ydd_jmT6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD2H6utRydGv"
      },
      "source": [
        "Вы почти готовы обучать свою модель. На последнем этапе предварительной обработки вы примените слой TextVectorization, созданный ранее, к набору данных обучения, проверки и тестирования."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.410598Z",
          "iopub.status.busy": "2023-07-27T05:30:11.409892Z",
          "iopub.status.idle": "2023-07-27T05:30:11.541074Z",
          "shell.execute_reply": "2023-07-27T05:30:11.540426Z"
        },
        "id": "2zhmpeViI1iG"
      },
      "outputs": [],
      "source": [
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsVQyPMizjuO"
      },
      "source": [
        "### Настройте набор данных для повышения производительности\n",
        "\n",
        "Это два важных метода, которые следует использовать при загрузке данных, чтобы гарантировать, что ввод-вывод не блокируется.\n",
        "\n",
        "`.cache()` сохраняет данные в памяти после их загрузки с диска. Это гарантирует, что набор данных не станет узким местом при обучении вашей модели. Если ваш набор данных слишком велик, чтобы поместиться в памяти, вы также можете использовать этот метод для создания высокопроизводительного дискового кэша, чтение которого более эффективно, чем чтение многих небольших файлов.\n",
        "\n",
        "`.prefetch()` перекрывает предварительную обработку данных и выполнение модели во время обучения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.544660Z",
          "iopub.status.busy": "2023-07-27T05:30:11.544420Z",
          "iopub.status.idle": "2023-07-27T05:30:11.553635Z",
          "shell.execute_reply": "2023-07-27T05:30:11.553023Z"
        },
        "id": "wMcs_H7izm5m"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLC02j2g-llC"
      },
      "source": [
        "### Создайте модель\n",
        "\n",
        "Пришло время создать свою нейронную сеть:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.556769Z",
          "iopub.status.busy": "2023-07-27T05:30:11.556542Z",
          "iopub.status.idle": "2023-07-27T05:30:11.559456Z",
          "shell.execute_reply": "2023-07-27T05:30:11.558829Z"
        },
        "id": "dkQP6in8yUBR"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.562294Z",
          "iopub.status.busy": "2023-07-27T05:30:11.562048Z",
          "iopub.status.idle": "2023-07-27T05:30:11.619336Z",
          "shell.execute_reply": "2023-07-27T05:30:11.618749Z"
        },
        "id": "xpKOoWgu-llD"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(1)])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PbKQ6mucuKL"
      },
      "source": [
        "Слои укладываются последовательно для построения классификатора:\n",
        "\n",
        "1. Первый слой — это слой «Встраивание». Этот уровень принимает обзоры в целочисленной кодировке и ищет вектор внедрения для каждого индекса слова. Эти векторы изучаются по мере обучения модели. Векторы добавляют размерность к выходному массиву. Результирующие измерения: `(партия, последовательность, внедрение)`.  \n",
        "\n",
        "2. Затем слой GlobalAveragePooling1D возвращает выходной вектор фиксированной длины для каждого примера путем усреднения по измерению последовательности. Это позволяет модели обрабатывать входные данные переменной длины самым простым способом.\n",
        "3. Последний слой плотно связан с одним выходным узлом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4EqVWg4-llM"
      },
      "source": [
        "### Функция потерь и оптимизатор\n",
        "\n",
        "Модель нуждается в функции потерь и оптимизаторе для обучения. Поскольку это проблема двоичной классификации, и модель выводит вероятность (одноединичный слой с сигмовидной активацией), вы будете использовать функцию потерь `losses.BinaryCrossentropy`.\n",
        "\n",
        "Теперь настройте модель для использования оптимизатора и функции потерь:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.628014Z",
          "iopub.status.busy": "2023-07-27T05:30:11.627767Z",
          "iopub.status.idle": "2023-07-27T05:30:11.642802Z",
          "shell.execute_reply": "2023-07-27T05:30:11.642094Z"
        },
        "id": "Mr0GP-cQ-llN"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35jv_fzP-llU"
      },
      "source": [
        "### Обучите модель\n",
        "\n",
        "Вы обучите модель, передав объект dataset методу fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:30:11.646010Z",
          "iopub.status.busy": "2023-07-27T05:30:11.645752Z",
          "iopub.status.idle": "2023-07-27T05:31:20.221406Z",
          "shell.execute_reply": "2023-07-27T05:31:20.220680Z"
        },
        "id": "tXSGrjWZ-llW"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EEGuDVuzb5r"
      },
      "source": [
        "### Оцените модель\n",
        "\n",
        "Посмотрим, как поведет себя модель. Будут возвращены два значения. Потеря (число, обозначающее нашу ошибку, чем меньше значение, тем лучше) и точность."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:31:20.225497Z",
          "iopub.status.busy": "2023-07-27T05:31:20.224817Z",
          "iopub.status.idle": "2023-07-27T05:31:21.761000Z",
          "shell.execute_reply": "2023-07-27T05:31:21.760355Z"
        },
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1iEXVTR0Z2t"
      },
      "source": [
        "Этот довольно наивный подход обеспечивает точность около 86%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldbQqCw2Xc1W"
      },
      "source": [
        "### Создайте график точности и потерь с течением времени\n",
        "\n",
        "`model.fit()` возвращает объект `History`, который содержит словарь со всем, что произошло во время обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:31:21.764662Z",
          "iopub.status.busy": "2023-07-27T05:31:21.764195Z",
          "iopub.status.idle": "2023-07-27T05:31:21.768851Z",
          "shell.execute_reply": "2023-07-27T05:31:21.768217Z"
        },
        "id": "-YcvZsdvWfDf"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_CH32qJXruI"
      },
      "source": [
        "Имеется четыре записи: по одной для каждой метрики, отслеживаемой во время обучения и проверки. Вы можете использовать их для построения графика потерь при обучении и проверке для сравнения, а также точности обучения и проверки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:31:21.771984Z",
          "iopub.status.busy": "2023-07-27T05:31:21.771772Z",
          "iopub.status.idle": "2023-07-27T05:31:21.936608Z",
          "shell.execute_reply": "2023-07-27T05:31:21.936041Z"
        },
        "id": "2SEMeQ5YXs8z"
      },
      "outputs": [],
      "source": [
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:31:21.939979Z",
          "iopub.status.busy": "2023-07-27T05:31:21.939607Z",
          "iopub.status.idle": "2023-07-27T05:31:22.094837Z",
          "shell.execute_reply": "2023-07-27T05:31:22.094249Z"
        },
        "id": "Z3PJemLPXwz_"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFFyCuJoXy7r"
      },
      "source": [
        "На этом графике точки представляют потери при обучении и точность, а сплошные линии — потери и точность при проверке.\n",
        "\n",
        "Обратите внимание, что потери при обучении *уменьшаются* с каждой эпохой, а точность обучения *увеличивается* с каждой эпохой. Это ожидается при использовании оптимизации градиентного спуска — она должна минимизировать желаемое количество на каждой итерации.\n",
        "\n",
        "Это не относится к потерям при проверке и точности — похоже, они достигают пика перед точностью обучения. Это пример переобучения: модель работает лучше на обучающих данных, чем на данных, которые она никогда раньше не видела. После этого момента модель чрезмерно оптимизируется и изучает представления, *специфичные* для обучающих данных, которые не *обобщаются* для тестовых данных.\n",
        "\n",
        "В этом конкретном случае вы можете предотвратить переобучение, просто остановив обучение, когда точность проверки перестает увеличиваться. Один из способов сделать это — использовать обратный вызов tf.keras.callbacks.EarlyStopping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-to23J3Vy5d3"
      },
      "source": [
        "## Экспортируем модель\n",
        "\n",
        "В приведенном выше коде вы применили слой TextVectorization к набору данных перед подачей текста в модель. Если вы хотите, чтобы ваша модель могла обрабатывать необработанные строки (например, чтобы упростить ее развертывание), вы можете включить слой TextVectorization внутри вашей модели. Для этого вы можете создать новую модель, используя только что обученные веса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:31:22.097928Z",
          "iopub.status.busy": "2023-07-27T05:31:22.097675Z",
          "iopub.status.idle": "2023-07-27T05:31:25.097508Z",
          "shell.execute_reply": "2023-07-27T05:31:25.096810Z"
        },
        "id": "FWXsMvryuZuq"
      },
      "outputs": [],
      "source": [
        "export_model = tf.keras.Sequential([\n",
        "  vectorize_layer,\n",
        "  model,\n",
        "  layers.Activation('sigmoid')\n",
        "])\n",
        "\n",
        "export_model.compile(\n",
        "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Test it with `raw_test_ds`, which yields raw strings\n",
        "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwQgoN88LoEF"
      },
      "source": [
        "### Вывод по новым данным\n",
        "\n",
        "Чтобы получить прогнозы для новых примеров, вы можете просто вызвать model.predict().."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-27T05:31:25.101055Z",
          "iopub.status.busy": "2023-07-27T05:31:25.100797Z",
          "iopub.status.idle": "2023-07-27T05:31:25.269157Z",
          "shell.execute_reply": "2023-07-27T05:31:25.268527Z"
        },
        "id": "QW355HH5L49K"
      },
      "outputs": [],
      "source": [
        "examples = [\"bad film\"]\n",
        "\n",
        "export_model.predict(examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaxlpFWpzR6c"
      },
      "source": [
        "Включение логики предварительной обработки текста в вашу модель позволяет экспортировать модель для производства, что упрощает развертывание и снижает вероятность [перекоса при обучении/тестировании]\n",
        "\n",
        "При выборе места применения слоя TextVectorization следует учитывать разницу в производительности. Использование его вне вашей модели позволяет вам выполнять асинхронную обработку ЦП и буферизацию данных при обучении на графическом процессоре. Итак, если вы тренируете свою модель на графическом процессоре, вы, вероятно, захотите использовать этот вариант, чтобы получить максимальную производительность при разработке вашей модели, а затем переключиться на включение слоя TextVectorization внутри вашей модели, когда вы будете готовы подготовиться к развертыванию. .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSSuci_6nCEG"
      },
      "source": [
        "## Упражнение: многоклассовая классификация\n",
        "\n",
        "В этом руководстве показано, как с нуля обучить двоичный классификатор на наборе данных IMDB. В качестве упражнения вы можете изменить этот блокнот, чтобы обучить многоклассовый классификатор предсказывать тег вопроса по программированию в [Stack Overflow](http://stackoverflow.com/).\n",
        "\n",
        "Для вас подготовлен [набор данных](https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz), содержащий несколько тысяч вопросов по программированию (например, «Как могу ли я отсортировать словарь по значению в Python?»), опубликованное в Stack Overflow. Каждый из них помечен ровно одним тегом (Python, CSharp, JavaScript или Java). Ваша задача — принять вопрос в качестве входных данных и спрогнозировать соответствующий тег, в данном случае Python.\n",
        "\n",
        "Набор данных, с которым вы будете работать, содержит несколько тысяч вопросов, извлеченных из гораздо более крупного общедоступного набора данных Stack Overflow на сайте [BigQuery](https://console.cloud.google.com/marketplace/details/stack-exchange/stack-overflow), который содержит более 17 миллионов постов.\n",
        "\n",
        "Загрузив набор данных, вы обнаружите, что его структура каталогов аналогична набору данных IMDB, с которым вы работали ранее:\n",
        "\n",
        "```\n",
        "train/\n",
        "...python/\n",
        "......0.txt\n",
        "......1.txt\n",
        "...javascript/\n",
        "......0.txt\n",
        "......1.txt\n",
        "...csharp/\n",
        "......0.txt\n",
        "......1.txt\n",
        "...java/\n",
        "......0.txt\n",
        "......1.txt\n",
        "```\n",
        "\n",
        "Примечание. Чтобы повысить сложность задачи классификации, слова Python, CSharp, JavaScript или Java в вопросах по программированию были заменены словом *пробел* (поскольку многие вопросы содержат язык, о котором они говорят).\n",
        "\n",
        "Чтобы выполнить это упражнение, вам следует изменить этот блокнот для работы с набором данных Stack Overflow, внеся следующие изменения:\n",
        "\n",
        "1. В верхней части записной книжки обновите код, загружающий набор данных IMDB, кодом для загрузки [набора данных Stack Overflow](https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar. gz), который уже подготовлен. Поскольку набор данных Stack Overflow имеет аналогичную структуру каталогов, вам не потребуется вносить много изменений.\n",
        "\n",
        "1. Измените последний слой вашей модели на «Dense(4)», так как теперь существует четыре выходных класса.\n",
        "\n",
        "1. При компиляции модели измените потерю на `tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)`. Это правильная функция потерь, которую можно использовать для задачи классификации нескольких классов, когда метки каждого класса являются целыми числами (в этом случае они могут быть 0, *1*, *2* или *3*). Кроме того, измените метрику на `metrics=['accuracy']`, поскольку это проблема классификации нескольких классов (`tf.metrics.BinaryAccuracy` используется только для двоичных классификаторов).\n",
        "\n",
        "1. При построении графика точности во времени измените `binary_accuracy` и `val_binary_accuracy` на `accuracy` и `val_accuracy` соответственно.\n",
        "\n",
        "1. Как только эти изменения будут завершены, вы сможете обучать многоклассовый классификатор."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}